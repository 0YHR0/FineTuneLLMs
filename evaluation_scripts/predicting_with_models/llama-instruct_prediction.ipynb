{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be96bd-de36-48cd-8ecd-4f6048a8b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from torch import cuda, bfloat16\n",
    "\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b304279-e44b-41e4-9e9b-15aafc1572d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'REELICIT/Llama-2-7b-chat-hf-ReqBrain'\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, use_fast = False)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdb1fb-447a-4033-81e1-2ff0bde8487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "___inst = tokenizer.convert_ids_to_tokens(tokenizer(\"[/INST]\")[\"input_ids\"])[1:]\n",
    "___java = tokenizer.convert_ids_to_tokens(tokenizer(\"```java\")[\"input_ids\"])#[1:]\n",
    "___end_of_ = tokenizer.convert_ids_to_tokens(tokenizer(\"/end_of_\")[\"input_ids\"])[1:]\n",
    "___user = tokenizer.convert_ids_to_tokens(tokenizer(\"[/user]\")[\"input_ids\"])[1:]\n",
    "___inst_small = tokenizer.convert_ids_to_tokens(tokenizer(\"[/Inst\")[\"input_ids\"])[1:]\n",
    "___hash_tag = tokenizer.convert_ids_to_tokens(tokenizer(\"#\")[\"input_ids\"])[1:]\n",
    "___star = tokenizer.convert_ids_to_tokens(tokenizer(\"*\")[\"input_ids\"])[1:]\n",
    "\n",
    "stop_token_ids = [\n",
    "    tokenizer.convert_tokens_to_ids(x) for x in [___inst, ___inst_small, [tokenizer.eos_token], ___end_of_, ___user, ['```'], ___hash_tag, ___star]\n",
    "]\n",
    "\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fa892-abd9-49fa-9dd3-4a27457a9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78368713-e09e-4cef-855a-7b7412813276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopping_criteria(\n",
    "#     torch.LongTensor([tokenizer.convert_tokens_to_ids(_)]).to(device),\n",
    "#     torch.FloatTensor([0.0])\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50a943-e82d-441b-a3ff-5aaa443b06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    return_full_text = True, # Set it to True when combining with LangChain\n",
    "    task='text-generation',\n",
    "    device=device,\n",
    "    stopping_criteria = stopping_criteria,  \n",
    "    temperature = 0.1,\n",
    "    top_p = 0.15,  \n",
    "    top_k = 0,  \n",
    "    max_new_tokens = 512,  \n",
    "    repetition_penalty = 1.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4e48f-be4a-4d68-b586-1049de280188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "evaluation_set = datasets.load_from_disk(\"./models_prediction_dataset\")\n",
    "evaluation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e36ecd-15b0-4a35-93c5-4f03d7e6caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "completion = []\n",
    "\n",
    "for query in tqdm(evaluation_set['query']):\n",
    "    result = result = pipe(f\"<s>[INST] {query} [/INST]\")\n",
    "    result = result[0]['generated_text'].split('[/INST]')[-1].strip(\"[/INST]\")\n",
    "    result = result.strip(\"```java\")\n",
    "    result = result.strip(\"/end_of_\")\n",
    "    result = result.strip(\" \")\n",
    "    result = result.strip(\"[/user]\")\n",
    "    result = result.strip(\"[/Inst\")\n",
    "    result = result.strip(\"```\")\n",
    "    result = result.strip(\"#\")\n",
    "    result = result.strip(\"*\")\n",
    "    result = result.strip(\" \")\n",
    "    completion.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150213a3-3092-4509-8e35-2fbbbf65c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set = evaluation_set.add_column(\"llama2_7b_chat_hf_preds\", completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c45371-9cc9-4e1d-87f5-715db7749ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set.save_to_disk(\"./models_prediction_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
