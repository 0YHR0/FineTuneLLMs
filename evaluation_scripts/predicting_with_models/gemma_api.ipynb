{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f7a252-4cb0-41c4-bb4b-53784ae362d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "path = \"\"\n",
    "dataset_before = datasets.load_from_disk(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e39921-02ef-403c-b96c-5384442cebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2371d2-5168-47a6-a359-e9d7310dd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_before[1]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c5f2c-5871-4436-bd63-a60a30797369",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_before[1]['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385706ee-3fa4-42de-8886-e34fa86918b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_before[1]['input_for_gemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bbb8d3-2726-4a0a-972e-75acd4bd5907",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token_ids = [\n",
    "    tokenizer.convert_tokens_to_ids(x) for x in [[tokenizer.eos_token], [\"<\", \"|\", \"user\"]]\n",
    "]\n",
    "\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
    "\n",
    "\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed83ef8-7fa7-48c8-ba43-1aa1bda13566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://xxxx.xxxx.aws.endpoints.huggingface.cloud\"\n",
    "headers = {\n",
    "\t\"Accept\" : \"application/json\",\n",
    "\t\"Authorization\": \"Bearer xxxx\",\n",
    "\t\"Content-Type\": \"application/json\" \n",
    "}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\n",
    "output = query({\n",
    "\t\"inputs\": \"Can you please let us know more details about your \",\n",
    "\t\"parameters\": {\n",
    "        \"top_k\": 0,\n",
    "\t\t\"top_p\": 0.15,\n",
    "\t\t\"temperature\": 0.2,\n",
    "\t\t\"max_new_tokens\": 512,\n",
    "        \n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781b18c-8ba8-4c0f-9e68-c10565818b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "completion = []\n",
    "\n",
    "# instruction = \"You are a professional requirements engineer who helps users brainstorm more software requirements.\"\n",
    "\n",
    "for input_for_gemma in tqdm(dataset_before['input_for_gemma']):\n",
    "    # result = pipe(f\"<|system|>\\n{instruction}\\n<|user|>\\n{query}\\n<|assistant|>\\n\")\n",
    "    result = query({\n",
    "\t\"inputs\": input_for_gemma,\n",
    "\t\"parameters\": {}\n",
    "})\n",
    "    \n",
    "    # result = pipe(input_for_gemma)\n",
    "    result = result[0]['generated_text'].split('\\n<|assistant|>\\n')[-1]\n",
    "    # result = result.strip(\" \")\n",
    "    print('```````````````````````````')\n",
    "    print(result)\n",
    "    completion.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8608ff-2687-48b6-ad00-25f1bbd1d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = dataset_before.add_column(\"gemma_preds\", completion)\n",
    "updated_dataset.save_to_disk(\"E:\\\\files\\\\Stuttgart\\\\Thesis\\\\NLP\\\\saved_datasets\\\\final_dataset_gemma_09052024\\\\my_gemma_after_prediction_16052024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba993b53-2bdc-43dc-bb1d-d2b8e92f5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_dict = updated_dataset.to_dict()\n",
    "\n",
    "with open('E:\\\\files\\\\Stuttgart\\\\Thesis\\\\NLP\\\\saved_datasets\\\\final_dataset_gemma_09052024\\\\my_gemma_after_prediction_16052024.json', 'w') as f:\n",
    "    json.dump(dataset_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49015211-e976-48bc-a6df-51eaa49e6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama2_datasets = datasets.load_from_disk(\"E:\\\\files\\\\Stuttgart\\\\Thesis\\\\NLP\\\\saved_datasets\\\\final_dataset_for_training_17042024\\\\my_llama_after_prediction_01052024\")\n",
    "\n",
    "\n",
    "dataset_dict = llama2_datasets.to_dict()\n",
    "with open('E:\\\\files\\\\Stuttgart\\\\Thesis\\\\NLP\\\\saved_datasets\\\\final_dataset_gemma_09052024\\\\my_llama_after_prediction_16052024.json', 'w') as f:\n",
    "    json.dump(dataset_dict, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da35fe6-d891-4721-8f69-a449f60dd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from datasets import Dataset\n",
    "with open('E:\\\\files\\\\Stuttgart\\\\Thesis\\\\NLP\\\\saved_datasets\\\\final_dataset_gemma_09052024\\\\my_gemma_after_prediction_23052024.json', 'r') as f:\n",
    "    dataset_dict_gemma = json.load(f)\n",
    "\n",
    "# 将字典数据转换为 datasets.Dataset\n",
    "dataset = Dataset.from_dict(dataset_dict_gemma)\n",
    "\n",
    "print(dataset[0]['gemma_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cec16a-6e61-4c19-ab0d-02d26bcefeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    print('``````````````````````',i,)\n",
    "    print(dataset[i]['gemma_preds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66be4ccc-03cd-47f0-8cfa-85a73bc35a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(\"E:\\\\files\\\\Stuttgart\\\\Thesis\\\\NLP\\\\saved_datasets\\\\final_dataset_gemma_09052024\\\\my_gemma_after_prediction_23052024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81df1125-b167-4c6a-be7e-6a69a798ef88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
