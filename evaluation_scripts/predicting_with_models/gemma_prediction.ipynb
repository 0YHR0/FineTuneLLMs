{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be96bd-de36-48cd-8ecd-4f6048a8b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from torch import cuda, bfloat16\n",
    "\n",
    "\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388a4bb-b2e7-46f2-8e6e-37343a14f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda:0')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcc832-877d-47fb-aa4b-3f0cb1bdda4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -U \"transformers==4.38.0\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b304279-e44b-41e4-9e9b-15aafc1572d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Kastanie99/gemma-1.1-7b-it-haoran-mt-09052024'\n",
    "\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name, use_fast = False)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Model loaded on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcdb1fb-447a-4033-81e1-2ff0bde8487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_token_ids = [\n",
    "    tokenizer.convert_tokens_to_ids(x) for x in [[tokenizer.eos_token], [\"<\", \"|\", \"user\"]]\n",
    "]\n",
    "\n",
    "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106fa892-abd9-49fa-9dd3-4a27457a9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "\n",
    "class StopOnTokens(StoppingCriteria):\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        for stop_ids in stop_token_ids:\n",
    "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c50a943-e82d-441b-a3ff-5aaa443b06e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = transformers.pipeline(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    return_full_text = True, # Set it to True when combining with LangChain\n",
    "    task = 'text-generation',\n",
    "    device = device,\n",
    "    stopping_criteria=stopping_criteria,  \n",
    "    temperature = 0.2,\n",
    "    top_p = 0.15,  \n",
    "    top_k=0,  \n",
    "    max_new_tokens = 512,  \n",
    "    repetition_penalty = 1.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4e48f-be4a-4d68-b586-1049de280188",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "evaluation_set = datasets.load_from_disk(\"/pfs/data5/home/st/st_us-051500/st_st180358/gemma_training/my_gemma_combined_dataset_test_09052024\")\n",
    "evaluation_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3625ef3-35ad-44a8-91d7-3c1f88845267",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_set[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021de6d-0b6e-47dd-bf1b-5635b3b709d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fields(example):\n",
    "\n",
    "    query_start = example['text'].find('<|user|>') + 10  # 找到 '#' 的索引，并向后移动一位\n",
    "    query_end = example['text'].find('<|assistant|>')  # 找到 '%' 的索引\n",
    "    query_part = example['text'][query_start:query_end]  # 切片获取两个索引之间的字符串\n",
    "\n",
    "    completion_start = example['text'].find('<|assistant|>') + 15\n",
    "    completion_part = example['text'][completion_start:]\n",
    "\n",
    "    input_end = example['text'].find('<|assistant|>')\n",
    "    input_for_gemma = example['text'][:input_end] + '<|assistant|>\\n'\n",
    "    \n",
    "    # 从文本中分割出所需内容\n",
    "    # parts = example['text'].split('\"\\n\\n')\n",
    "    # query_part = parts[0].split('\"')[-1].strip()\n",
    "    # completion_part = parts[1].split('Rewritten requirement:\\n\"')[-1].strip().rstrip('\"')\n",
    "    \n",
    "    # 返回新的字段\n",
    "    return {'query': query_part, 'completion': completion_part, 'input_for_gemma': input_for_gemma}\n",
    "\n",
    "# 应用map函数\n",
    "updated_dataset = evaluation_set.map(extract_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e221ec-9a9c-4eb8-9a27-9410dd1d9a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca8e4d-d68f-4dcf-adcf-d22c81b429da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print(updated_dataset[1]['input_for_gemma'])    \n",
    "print(\"``````````````````````\")\n",
    "print(updated_dataset[1]['query'])\n",
    "print(\"``````````````````````\")\n",
    "print(updated_dataset[1]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73aad31-8727-4535-844d-1852d7f00bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/gemma_training/my_gemma_before_prediction_09052024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354384d-4306-4147-bbe6-75b4b06eeda6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7f491-6041-4309-8aa1-0517684dc91f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0b2f6-2ae9-4346-9856-326f84f82286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e36ecd-15b0-4a35-93c5-4f03d7e6caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "completion = []\n",
    "\n",
    "# instruction = \"You are a professional requirements engineer who helps users brainstorm more software requirements.\"\n",
    "\n",
    "for input_for_gemma in tqdm(updated_dataset['input_for_gemma']):\n",
    "    # result = pipe(f\"<|system|>\\n{instruction}\\n<|user|>\\n{query}\\n<|assistant|>\\n\")\n",
    "    result = pipe(input_for_gemma)\n",
    "    result = result[0]['generated_text'].split('\\n<|assistant|>\\n')[-1]\n",
    "    # result = result.strip(\" \")\n",
    "    completion.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738fb33-7637-4672-994f-4f6e4d6aeb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset = updated_dataset.add_column(\"gemma_preds\", completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07ef1d-4fe7-45c2-8a10-85a7aba77e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_dataset.save_to_disk(\"/pfs/data5/home/st/st_us-051500/st_st180358/gemma_training/my_gemma_after_prediction_09052024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f921937-9dee-4c09-abab-0f045ed0f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_dataset)\n",
    "print(\"```````````````````````\")\n",
    "print(updated_dataset[25]['query'])\n",
    "print(\"```````````````````````\")\n",
    "print(updated_dataset[25]['gemma_preds'])\n",
    "print(\"```````````````````````\")\n",
    "print(updated_dataset[25]['completion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a225a7-2b53-4949-b036-d74eca51e26b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
