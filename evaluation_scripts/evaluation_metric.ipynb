{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f295e5-f16e-4343-a733-ef61a294446d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/REELICIT/reqbrain_rep_package/blob/3344cfbf610656025f7c0cfa9ae7a313bfdcd0c6/evaluation_scripts/evaluation_two_metric.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927387e-4ceb-494c-88be-28c1a875be92",
   "metadata": {},
   "source": [
    "# Common imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c882c2-ce9f-4020-972e-76cf3f38c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de20d6fa-b40c-4f2d-999f-a99404e841e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f31bcc-ac6c-4211-9e83-66e5a5078e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a01c504-1973-4d82-be87-cf47f78dc2bc",
   "metadata": {},
   "source": [
    "# Loading the Instruct Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2109b1-99d4-4d7e-9c46-9a242a99bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_dataset = datasets.load_from_disk('/home/st/st_us-051500/st_st180358/llama_training/my_zepyra_after_prediction_01052024')\n",
    "print(llama_dataset)\n",
    "zephyr_dataset = datasets.load_from_disk('/pfs/data5/home/st/st_us-051500/st_st180358/zephyr_training/my_zepyra_after_prediction_17040204')\n",
    "print(zephyr_dataset)\n",
    "llama3_dataset = datasets.load_from_disk('/home/st/st_us-051500/st_st180358/llama3_training/my_llama3_after_prediction_08052024')\n",
    "gemma_dataset = datasets.load_from_disk('/home/st/st_us-051500/st_st180358/my_gemma_after_prediction_23052024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad43501e-51bd-475a-8533-d0c917e37eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the human written requirements\n",
    "\n",
    "llama_references = llama_dataset['completion']\n",
    "zephyr_references = zephyr_dataset['completion']\n",
    "llama3_references = llama3_dataset['completion']\n",
    "\n",
    "gemma_dataset_references = gemma_dataset['completion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39293bd9-1a97-4c0d-ac5f-18f7d3b81db0",
   "metadata": {},
   "source": [
    "# Putting all Metrics Togather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8755cc-683f-4595-897d-31ab7174e6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(references, predictions):\n",
    "    # bert score\n",
    "    bertscore = evaluate.load('bertscore')\n",
    "    bertscore_results = bertscore.compute(predictions = predictions, references = references, model_type = \"xlm-mlm-en-2048\", lang = 'en')\n",
    "    # frugal score\n",
    "    frugalscore = evaluate.load(\"frugalscore\", \"moussaKam/frugalscore_medium_roberta_bert-score\")\n",
    "    frugalscore_results = frugalscore.compute(predictions=predictions, references=references, batch_size = 16, max_length = 512, device = \"gpu\")\n",
    "    # TER score\n",
    "    terscore = evaluate.load('ter')\n",
    "    terscore_results = terscore.compute(predictions=predictions, references=references, case_sensitive=True)\n",
    "    # BLEU score\n",
    "    bleuscore = evaluate.load(\"bleu\")\n",
    "    bleuscore_results = bleuscore.compute(predictions=predictions, references=references)\n",
    "    # ROUGE score\n",
    "    rougescore = evaluate.load(\"rouge\")\n",
    "    rougescore_results = rougescore.compute(predictions=predictions, references=references)\n",
    "    # Exact match score\n",
    "    exactmatchscore = evaluate.load(\"exact_match\")\n",
    "    predictions_word_arrays = [sentence.split() for sentence in predictions]\n",
    "    print(len(predictions_word_arrays))\n",
    "    references_word_arrays = [sentence.split() for sentence in references]\n",
    "    print(len(references_word_arrays))\n",
    "    re = []\n",
    "    for index in range(len(predictions_word_arrays)):\n",
    "        max_length = max(len(predictions_word_arrays[index]), len(references_word_arrays[index]))\n",
    "\n",
    "# 用\"pad\"填充数组\n",
    "        predictions_word_arrays[index] = predictions_word_arrays[index] + [\"pad\"] * (max_length - len(predictions_word_arrays[index]))\n",
    "        references_word_arrays[index] = references_word_arrays[index] + [\"pad\"] * (max_length - len(references_word_arrays[index]))\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        re.append(exactmatchscore.compute(predictions=predictions_word_arrays[index], references=references_word_arrays[index])['exact_match'])\n",
    "    exactmatchscore_results = sum(re) / len(re)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return {'bert_score': bertscore_results, 'frugal_score': frugalscore_results, 'ter_score': terscore_results, 'bleu_score': bleuscore_results, 'rouge_score': rougescore_results, 'exact_match_score': exactmatchscore_results}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2646fcd5-c52a-40d7-b2e2-161482e5fa1c",
   "metadata": {},
   "source": [
    "# Evaluating Trained Models using NLP Human Correlation Metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec273d9-6f85-42b2-b871-d52525b70d87",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddd4437-808d-448c-a8ac-62dfc16911a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff15159-2d1c-4d03-8f60-efa0bb1c19ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4fff80-7e18-43e0-a70d-9f2ec150cae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6de9a-acba-406d-9249-9c5b6536dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91642738-b8b7-47ee-a1ed-3c7730a289d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate zephyr\n",
    "zephyr_results = evaluate_model(zephyr_references, zephyr_dataset['zephyr_7b_beta_preds'])\n",
    "# Evaluate llama\n",
    "llama_results = evaluate_model(llama_references, llama_dataset['llama2_7b_chat_hf_preds'])\n",
    "# Evaluate llama3\n",
    "llama3_results = evaluate_model(llama3_references, llama3_dataset['llama3_8B_Instruct_preds'])\n",
    "gemma_results = evaluate_model(gemma_dataset_references, gemma_dataset['gemma_preds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0970c3a-47b9-4c6d-8cf0-83c770fc8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e3ce2-7403-4222-9af8-6ca7333fb55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(zephyr_results)\n",
    "print(gemma_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75932ae7-5f40-4e28-80b7-1b4435864a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path_zephyr = '/pfs/data5/home/st/st_us-051500/st_st180358/zephyr_training/zephyr_evaluation_results_24052024.json'\n",
    "file_path_llama = '/pfs/data5/home/st/st_us-051500/st_st180358/llama_training/llama_evaluation_results_24052024.json'\n",
    "file_path_llama3 = '/pfs/data5/home/st/st_us-051500/st_st180358/llama3_training/llama3_evaluation_results_24052024.json'\n",
    "file_path_gemma = '/pfs/data5/home/st/st_us-051500/st_st180358/gemma_training/gemma_evaluation_results_24052024.json'\n",
    "# print(type(zephyr_results))\n",
    "\n",
    "def convert_float32_to_float(d):\n",
    "    if isinstance(d, dict):\n",
    "        for key, value in d.items():\n",
    "            d[key] = convert_float32_to_float(value)\n",
    "    elif isinstance(d, list):\n",
    "        for i in range(len(d)):\n",
    "            d[i] = convert_float32_to_float(d[i])\n",
    "    elif isinstance(d, np.float32):\n",
    "        return float(d)\n",
    "    return d\n",
    "\n",
    "llama_results = convert_float32_to_float(llama_results)\n",
    "zephyr_results = convert_float32_to_float(zephyr_results)\n",
    "llama3_results = convert_float32_to_float(llama3_results)\n",
    "gemma_results = convert_float32_to_float(gemma_results)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Save the result to disk\n",
    "with open(file_path_zephyr, 'w') as json_file:\n",
    "    json.dump(zephyr_results, json_file, indent=4)\n",
    "with open(file_path_gemma, 'w') as json_file:\n",
    "    json.dump(gemma_results, json_file, indent=4)\n",
    "with open(file_path_llama, 'w') as json_file:\n",
    "    json.dump(llama_results, json_file, indent=4)\n",
    "with open(file_path_llama3, 'w') as json_file:\n",
    "    json.dump(llama3_results, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57016321-f17a-44db-a9f1-74933d294d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gemma_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9b4f9-9921-466b-8195-5b7da0c439db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# used to generate a two formated columns for BERT and FRUGAL to be used for SPIDER chart on paper\n",
    "\n",
    "zephyr_frugal_score = results['frugal_score']['scores']\n",
    "zephyr_bert_score = results['bert_score']['recall']\n",
    "dataset_for_spider_chart = dataset.add_column('zephyr_frugal_score', zephyr_frugal_score)\n",
    "dataset_for_spider_chart = dataset_for_spider_chart.add_column('zephyr_bert_score', zephyr_bert_score)\n",
    "dataset_for_spider_chart.save_to_disk('/home/st/st_us-051500/st_st180358/zephyr_training/my_zepyra_result_for_spider_chart_17040204')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c5ec2-71eb-4828-8925-c3d9885f3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in list(results['bert_score'].keys())[:-1]:\n",
    "    pairwise_metric = results['bert_score'][metric]\n",
    "    averaged_metric = np.sum(pairwise_metric)/len(pairwise_metric)\n",
    "    print(f'\\033[1m {metric}:\\033[0m \\t', averaged_metric)\n",
    "print('.' * 150)\n",
    "\n",
    "pairwise_frugal_score = results['frugal_score']['scores']\n",
    "averaged_frugal_score = np.sum(results['frugal_score']['scores'])/len(results['frugal_score']['scores'])\n",
    "print('\\033[1m FRUGAL Score:\\033[0m \\t', averaged_frugal_score)\n",
    "print('.' * 150)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
