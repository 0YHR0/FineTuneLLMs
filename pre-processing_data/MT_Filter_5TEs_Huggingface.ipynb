{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7df53-0d34-40a1-ad4a-c97a21f7be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0546209-e876-4ebd-bdbe-df4c7d322775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288aede4-e619-4ac8-9f92-d5518aefd6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "# import numpy as np\n",
    "import torch\n",
    "import os\n",
    "# from transformers import pipeline\n",
    "from datasets import Dataset, load_dataset, Features, Value\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "\n",
    "GREEN = \"\\033[32m\"\n",
    "BLUE = \"\\033[34m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "print(GREEN, 'datasets version', RESET, datasets.__version__)\n",
    "\n",
    "path = \"\"\n",
    "# Load raw dataset\n",
    "raw_dataset = datasets.load_from_disk(path)\n",
    "print(BLUE, 'Loading dataset: ', RESET, raw_dataset)\n",
    "print('==========================')\n",
    "# Check insterested Label\n",
    "print(BLUE, 'check KM100L6V2 Label: ', RESET)\n",
    "print(np.unique(raw_dataset['KM100L6V2 Label'], return_counts=True))\n",
    "print(BLUE, 'check Sources Type Label: ', RESET)\n",
    "print(np.unique(raw_dataset['Sources Type'], return_counts=True))\n",
    "\n",
    "# Check env info\n",
    "print(GREEN, 'torch version: ', RESET, torch.__version__)\n",
    "print(GREEN, 'cuda available: ', RESET, torch.cuda.is_available())\n",
    "print(GREEN, 'GPU name: ', RESET, torch.cuda.get_device_name(0))\n",
    "print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd2c12-489e-47f8-a383-203d0709d4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the datasets: remove the columns not needed\n",
    "dataset = raw_dataset.remove_columns(\n",
    "    ['Requirement (EN)', 'Requirement (DE)', 'Requirement (Other Language)', 'Category (Source)',\n",
    "     'Sub Category (Source)', 'Category (NoRBERT)', 'Sub Category (NoRBERT)', 'Category (Manual)',\n",
    "     'Sub Category (Manual)', 'Open/ Closed Source', 'Date', 'Comment', 'Original Language Code', 'KM45L6V2 Label',\n",
    "     'KM35L6V2S3 Label', 'input_ids', 'token_type_ids', 'attention_mask', 'regex_tagged', '__index_level_0__'])\n",
    "print(BLUE, 'data set after remove columns: ', RESET, dataset)\n",
    "print('==========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a429f4-3fad-4b63-9fba-f6b11aabd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset with Sources Type = RE\n",
    "def filter_SourcesType(example):\n",
    "    return example['Sources Type'] == 'RE'\n",
    "\n",
    "\n",
    "filtered_dataset = dataset.filter(filter_SourcesType)\n",
    "print(BLUE, 'Filtered the dataset with Sources Type = RE', RESET, filtered_dataset)\n",
    "print('==========================')\n",
    "\n",
    "\n",
    "# Filter the dataset with KM100L6V2 Label = F\n",
    "def filter_KM100L6V2(example):\n",
    "    return example['KM100L6V2 Label'] == 'F' or example['KM100L6V2 Label'] == 'NF'\n",
    "\n",
    "\n",
    "filtered_dataset = filtered_dataset.filter(filter_KM100L6V2)\n",
    "print(BLUE, 'Filtered the dataset with KM100L6V2 Label = F', RESET, filtered_dataset)\n",
    "print('==========================')\n",
    "\n",
    "print(BLUE, \"Check a sample data: \", RESET, filtered_dataset[1])\n",
    "print('==========================')\n",
    "\n",
    "# Save the filtered dataset to disk\n",
    "filtered_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/filtered_dataset_Step1')\n",
    "print(GREEN, 'save the filtered data to disk', RESET)\n",
    "print('==========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb319b50-24f7-4df9-b986-d55ab7f1da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e43fc0-7d16-454a-bfdd-3b0aabc7c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from transformers import pipeline\n",
    "# Use model to further filter the data\n",
    "# Get the model\n",
    "pipe = transformers.pipeline(\"text-generation\", model=\"HuggingFaceH4/zephyr-7b-beta\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "print(GREEN, 'model downloaded: ', RESET, pipe)\n",
    "print('==========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65ef93e-63c0-4420-be20-95592969d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = '''\n",
    "<|system|> \\n\n",
    "You are a requirement engineer that helps me to classify requirements according to my needs,\n",
    "and your answer must starts with Yes or No.</s>\n",
    "'''\n",
    "\n",
    "# prompt: Nominalization\n",
    "prompt_TE_1 = ''' \\n\n",
    "<|user|> \\n\n",
    "Here is the definition of nominalization:\n",
    "Nominalization turns processes into single events, losing detailed information. \n",
    "A nominalized term must not allow for any leeway in the interpretation of the processes and must\n",
    "precisely depict the process, including any exceptions that may occur as well as all input and output parameters.\n",
    "For example, \"transmit\" becomes \"transmission\". Other typical examples of nominalization are the terms input, booking, and acceptance.\n",
    "\n",
    "And Here is the example of Nominalization:\n",
    "“In case of a system crash, a restart of the system shall be performed.”\n",
    "The terms system crash and restart each describe a process that thought to be\n",
    "analyzed more precisely.\\n\n",
    "\n",
    "With the definition and example: Please tell me if the following requirement text has the problem of Nominalization:\n",
    "'''\n",
    "\n",
    "# prompt: Nouns without reference index\n",
    "prompt_TE_2 = '''\\n\n",
    "<|user|> \\n\n",
    "Here is the definition of 'Nouns without reference index':\n",
    "As with process verbs, nouns are frequently incompletely specified. Linguists\n",
    "call this a missing or inadequate index of reference. Examples of\n",
    "terms that contain incompletely specified nouns are the user, the controller,\n",
    "the system, the message, the data, or the function.\n",
    "\n",
    "And Here is the example of Nouns without reference index:\n",
    "\"The data shall be displayed to the user on the terminal\"\n",
    "The following questions arise: What data exactly? Which user exactly?\n",
    "Which terminal exactly? If this information is amended, the requirement\n",
    "might thus read as follows:\n",
    "\"The system shall display the billing data to the registered user on the terminal\n",
    "she is logged in to.\"\n",
    "\n",
    "With the definition and example: Please tell me if the following requirement text has the problem of Nouns without reference index:\n",
    "'''\n",
    "\n",
    "\n",
    "# prompt: Universal Quantifiers\n",
    "prompt_TE_3 = '''\\n\n",
    "<|user|> \\n\n",
    "Here is the definition of 'Universal Quantifiers':\n",
    "Universal quantifiers specify amounts or frequencies. They group a set of\n",
    "objects and make a statement about the behavior of this set. When using\n",
    "universal quantifiers, there is the risk that the specified behavior or\n",
    "property does not apply to all objects within the specified set.\n",
    "It must be verified whether the specified behavior really applies to all\n",
    "objects summarized through the quantifiers. Universal quantifiers can be\n",
    "easily identified through trigger words such as never, always, no, none,\n",
    "every, all, some, or nothing.\n",
    "\n",
    "\n",
    "And Here is the example of Universal Quantifiers:\n",
    "\"The system shall show all data sets in every submenu.\"\n",
    "In this case, the following question must be asked: Really in every submenu?\n",
    "Really all data sets?\n",
    "\n",
    "With the definition and example: Please tell me if the following requirement text has the problem of Universal Quantifiers:\n",
    "'''\n",
    "\n",
    "\n",
    "# prompt: Incompletely Specified Conditions\n",
    "prompt_TE_4 = '''\\n\n",
    "<|user|> \\n\n",
    "Here is the definition of 'Incompletely Specified Conditions':\n",
    "Incompletely specified conditions are another indicator of a potential loss\n",
    "of information. Requirements that contain conditions specify the behavior\n",
    "that must occur when the condition is met. In addition, they must specify\n",
    "what behavior must occur if the condition is not met (the part that is often\n",
    "missing).Trigger words are, for instance, if … then, in case, whether, and depending\n",
    "on.\n",
    "\n",
    "And Here is the example of Incompletely Specified Conditions:\n",
    "\"The restaurant system shall offer all beverages to a registered guest over the age\n",
    "of 20 years.\"\n",
    "At least one aspect remains unspecified in the example above: Which beverages\n",
    "shall be offered to a guest that is 20 years or younger?\n",
    "\n",
    "With the definition and example: Please tell me if the following requirement text has the problem of Incompletely Specified Conditions:\n",
    "'''\n",
    "\n",
    "\n",
    "# prompt: Incompletely Specified Process Verbs\n",
    "prompt_TE_5 = '''\\n\n",
    "<|user|> \\n\n",
    "Here is the definition of 'Incompletely Specified Process Verbs':\n",
    "Some process verbs require more than one noun to be considered completely\n",
    "specified. The verb transmit, for instance, requires at least three\n",
    "supplements to be considered complete: what is being transmitted, from\n",
    "where it is being transmitted, and to where it is being transmitted.\n",
    "Similarly, adjectives and adverbs may need to be supplemented\n",
    "as well. It can mostly be avoided or kept to a minimum using the active voice.\n",
    "\n",
    "And Here is the example of Incompletely Specified Process Verbs:\n",
    "\"To log a user in, the login data is entered.\"\n",
    "It is unclear who enters the login Use active voice.\n",
    "data. It is also unclear where and how this is done.\n",
    "\n",
    "With the definition and example: Please tell me if the following requirement text has the problem of Incompletely Specified Process Verbs:\n",
    "'''\n",
    "\n",
    "assistant = '''\n",
    "</s>\n",
    "\\n<|assistant|>\\n\n",
    "'''\n",
    "\n",
    "input_TE_1 = instruction + prompt_TE_1  + 'The service must be user friendly and easy to access by the user' + assistant\n",
    "response = pipe(input_TE_1, max_length=350, truncation=True)[0]\n",
    "# print(response['generated_text'].split('\\n<|assistant|>\\n')[-1])\n",
    "print(response['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26f4aa8-cb5b-4e8e-af79-11906715e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "RED = \"\\033[31m\"  \n",
    "\n",
    "# Use the model downloaded to check_requirements\n",
    "def check_requirements_HF(instruction, prompt, text, model):\n",
    "    # （prompt + data）\n",
    "    input_text = instruction + prompt + text + assistant\n",
    "    response = model(input_text, max_length=350, truncation=True)[0]['generated_text'].split('\\n<|assistant|>\\n')[-1]\n",
    "    # print('response: ', response)\n",
    "    return response\n",
    "\n",
    "\n",
    "# map function, tag if a text has TE_1: nominalization\n",
    "def modify_TE_column(item):\n",
    "    print('checking text: ', item['text'])\n",
    "    # doing processing here...\n",
    "    response = []\n",
    "    response.append(check_requirements_HF(instruction, prompt_TE_1, item['text'], pipe))\n",
    "    response.append(check_requirements_HF(instruction, prompt_TE_2, item['text'], pipe))\n",
    "    response.append(check_requirements_HF(instruction, prompt_TE_3, item['text'], pipe))\n",
    "    response.append(check_requirements_HF(instruction, prompt_TE_4, item['text'], pipe))\n",
    "    response.append(check_requirements_HF(instruction, prompt_TE_5, item['text'], pipe))\n",
    "    print('response: ', response)\n",
    "    # print('==========================')\n",
    "    # print(response[0])\n",
    "    # print(type(response))\n",
    "    # print(type(response[0]))\n",
    "    for index, r in enumerate(response):\n",
    "        key = f'TE_{index}'\n",
    "        if 'Yes' in r:\n",
    "            print('==========================')\n",
    "            print('result TE_', index, ': Yes')\n",
    "            print('==========================')\n",
    "            item[key] = 'Yes'\n",
    "        elif 'No' in r:\n",
    "            print('==========================')\n",
    "            print('result TE_', index, ': No')\n",
    "            print('==========================')\n",
    "            item[key] = 'No'\n",
    "        else:\n",
    "            print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            print('result TE_', index, ': Error')\n",
    "            print('!!!!!!!!!!!!!!!!!!!!!!!!!!!!!')\n",
    "            item[key] = 'Error'\n",
    "    return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9d7b4c-5d82-4766-8402-227b96a90d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881bfd9-7cad-4fed-aa6a-149f71779784",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(BLUE, '============= Start Processing with model ============', RESET)\n",
    "\n",
    "# test with the test dataset\n",
    "# testset = filtered_dataset.select(range(6))\n",
    "testset = filtered_dataset\n",
    "\n",
    "num_shards = 100  # shards num, adjust according to the available resources and the size of dataset\n",
    "# index\n",
    "processed_shards = []\n",
    "\n",
    "# check which shard has been processed\n",
    "for i in range(num_shards):\n",
    "    shard_path = f'test_processed_shard_{i}'\n",
    "    if os.path.exists(shard_path):\n",
    "        processed_shards.append(i)\n",
    "\n",
    "for i in range(num_shards):\n",
    "    if i not in processed_shards:\n",
    "        # shard the dataset\n",
    "        shard = testset.shard(num_shards=num_shards, index=i)\n",
    "        # start processing here...\n",
    "        processed_shard = shard.map(modify_TE_column)\n",
    "        processed_shard.save_to_disk(f'test_processed_shard_{i}')\n",
    "        processed_shards.append(i)\n",
    "        # processed_batches.append(processed_shard)\n",
    "\n",
    "# combine the shards\n",
    "final_dataset = concatenate_datasets([Dataset.load_from_disk(f'test_processed_shard_{i}') for i in range(num_shards)])\n",
    "\n",
    "# Store the final dataset\n",
    "final_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/test_processed_dataset_Step1')\n",
    "\n",
    "\n",
    "# TO AVOID MORE EXAMPLES in the response, use like # in the instruction, then split[0] to get yes or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48df726b-5b79-459f-b43d-71a1bcdda1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = datasets.load_from_disk('/pfs/data5/home/st/st_us-051500/st_st180358/test_processed_dataset_Step1')\n",
    "print(raw_dataset)\n",
    "print(raw_dataset[0])\n",
    "print(raw_dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38143cd9-76b8-4173-88a8-541b0c12ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_dataset[13300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131b6d48-7295-450c-9363-5f59224fd377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_TE_0_Yes(example):\n",
    "    return example['TE_0'] == 'Yes'\n",
    "def filter_TE_1_Yes(example):\n",
    "    return example['TE_1'] == 'Yes'\n",
    "def filter_TE_2_Yes(example):\n",
    "    return example['TE_2'] == 'Yes'\n",
    "def filter_TE_3_Yes(example):\n",
    "    return example['TE_3'] == 'Yes'\n",
    "def filter_TE_4_Yes(example):\n",
    "    return example['TE_4'] == 'Yes'\n",
    "\n",
    "TE_0_dataset = raw_dataset.filter(filter_TE_0_Yes)\n",
    "TE_1_dataset = raw_dataset.filter(filter_TE_1_Yes)\n",
    "TE_2_dataset = raw_dataset.filter(filter_TE_2_Yes)\n",
    "TE_3_dataset = raw_dataset.filter(filter_TE_3_Yes)\n",
    "TE_4_dataset = raw_dataset.filter(filter_TE_4_Yes)\n",
    "\n",
    "TE_0_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/TE_0_dataset')\n",
    "TE_1_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/TE_1_dataset')\n",
    "TE_2_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/TE_2_dataset')\n",
    "TE_3_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/TE_3_dataset')\n",
    "TE_4_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/TE_4_dataset')\n",
    "\n",
    "print(BLUE,'================TE_0_dataset=================' ,RESET)\n",
    "print(TE_0_dataset)\n",
    "print(TE_0_dataset[103])\n",
    "\n",
    "print(BLUE,'================TE_1_dataset=================' ,RESET)\n",
    "print(TE_1_dataset)\n",
    "print(TE_1_dataset[103])\n",
    "\n",
    "print(BLUE,'================TE_2_dataset=================' ,RESET)\n",
    "print(TE_2_dataset)\n",
    "print(TE_2_dataset[103])\n",
    "\n",
    "print(BLUE,'================TE_3_dataset=================' ,RESET)\n",
    "print(TE_3_dataset)\n",
    "print(TE_3_dataset[103])\n",
    "\n",
    "print(BLUE,'================TE_4_dataset=================' ,RESET)\n",
    "print(TE_4_dataset)\n",
    "print(TE_4_dataset[103])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3754e03-fd3d-4356-adc0-93da4c26ad26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_TE_All_No(example):\n",
    "    return example['TE_0'] == 'No' and example['TE_1'] == 'No' and example['TE_2'] == 'No' and example['TE_3'] == 'No' and example['TE_4'] == 'No'\n",
    "\n",
    "TE_All_No_dataset = raw_dataset.filter(filter_TE_All_No)\n",
    "\n",
    "TE_All_No_dataset.save_to_disk('/pfs/data5/home/st/st_us-051500/st_st180358/TE_All_No_dataset')\n",
    "\n",
    "print(BLUE,'================TE_All_No_dataset=================' ,RESET)\n",
    "print(TE_All_No_dataset)\n",
    "print(TE_All_No_dataset[103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964209d-7eaf-416c-ad2f-85f4213f3ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
